<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Twin Prime Selection Bias</title>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono&family=Source+Serif+4:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #0a0a0a;
            --surface: #141414;
            --surface-2: #1e1e1e;
            --border: #2a2a2a;
            --text: #e5e5e5;
            --text-muted: #888;
            --accent: #3b82f6;
            --accent-2: #8b5cf6;
            --success: #22c55e;
            --warning: #f59e0b;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            font-family: 'Inter', -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 24px;
        }

        /* Navigation */
        nav {
            position: sticky;
            top: 0;
            background: rgba(10, 10, 10, 0.95);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid var(--border);
            z-index: 100;
            padding: 16px 0;
        }

        nav .container {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        nav .logo {
            font-weight: 600;
            font-size: 1.1rem;
            background: linear-gradient(135deg, var(--accent), var(--accent-2));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        nav ul {
            display: flex;
            list-style: none;
            gap: 24px;
        }

        nav a {
            color: var(--text-muted);
            text-decoration: none;
            font-size: 0.9rem;
            transition: color 0.2s;
        }

        nav a:hover, nav a.active {
            color: var(--text);
        }

        /* Hero */
        .hero {
            padding: 80px 0 60px;
            text-align: center;
            border-bottom: 1px solid var(--border);
        }

        .hero h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 16px;
            background: linear-gradient(135deg, var(--accent), var(--accent-2));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .hero .subtitle {
            font-size: 1.25rem;
            color: var(--text-muted);
            max-width: 600px;
            margin: 0 auto 32px;
        }

        .stat-box {
            display: inline-block;
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 24px 48px;
        }

        .stat-value {
            font-size: 3rem;
            font-weight: 700;
            color: var(--success);
            font-family: 'JetBrains Mono', monospace;
        }

        .stat-label {
            font-size: 0.875rem;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        /* Sections */
        section {
            padding: 60px 0;
            border-bottom: 1px solid var(--border);
        }

        section h2 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 8px;
        }

        section .section-desc {
            color: var(--text-muted);
            margin-bottom: 24px;
        }

        .chart-container {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 24px;
            margin-bottom: 24px;
        }

        .chart {
            width: 100%;
            height: 400px;
        }

        /* Grid */
        .grid-2 {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 24px;
        }

        /* Cards */
        .card {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 24px;
        }

        .card h3 {
            font-size: 1rem;
            font-weight: 600;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .card h3 .icon {
            font-size: 1.25rem;
        }

        /* Math */
        .math-block {
            background: var(--surface-2);
            border-radius: 8px;
            padding: 16px 20px;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            overflow-x: auto;
            margin: 16px 0;
        }

        code {
            font-family: 'JetBrains Mono', monospace;
            background: var(--surface-2);
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 0.875em;
        }

        /* State colors */
        .state-pp { color: #22c55e; }
        .state-pc { color: #3b82f6; }
        .state-cp { color: #8b5cf6; }
        .state-cc { color: #f59e0b; }

        /* Table */
        table {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.9rem;
        }

        th, td {
            padding: 12px 16px;
            text-align: left;
            border-bottom: 1px solid var(--border);
        }

        th {
            font-weight: 600;
            color: var(--text-muted);
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        td.mono {
            font-family: 'JetBrains Mono', monospace;
        }

        /* Paper Section Styles */
        .paper-section {
            padding: 80px 0;
        }

        .paper-container {
            max-width: 800px;
            margin: 0 auto;
            padding: 0 24px;
        }

        .paper-nav {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 24px;
            margin-bottom: 48px;
        }

        .paper-nav h3 {
            font-size: 0.875rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 16px;
        }

        .paper-nav ul {
            list-style: none;
        }

        .paper-nav li {
            margin-bottom: 8px;
        }

        .paper-nav a {
            color: var(--accent);
            text-decoration: none;
        }

        .paper-nav a:hover {
            text-decoration: underline;
        }

        .paper-content {
            font-family: 'Source Serif 4', Georgia, serif;
            font-size: 1.1rem;
            line-height: 1.8;
        }

        .paper-content h1 {
            font-family: 'Inter', sans-serif;
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: 24px;
            padding-bottom: 16px;
            border-bottom: 2px solid var(--accent);
        }

        .paper-content h2 {
            font-family: 'Inter', sans-serif;
            font-size: 1.5rem;
            font-weight: 600;
            margin: 48px 0 16px;
            color: var(--accent);
        }

        .paper-content h3 {
            font-family: 'Inter', sans-serif;
            font-size: 1.2rem;
            font-weight: 600;
            margin: 32px 0 12px;
        }

        .paper-content p {
            margin-bottom: 16px;
        }

        .paper-content ul, .paper-content ol {
            margin: 16px 0;
            padding-left: 32px;
        }

        .paper-content li {
            margin-bottom: 8px;
        }

        .paper-content table {
            margin: 24px 0;
            font-family: 'Inter', sans-serif;
            font-size: 0.95rem;
        }

        .paper-content .theorem {
            background: var(--surface);
            border-left: 4px solid var(--accent);
            padding: 20px 24px;
            margin: 24px 0;
            border-radius: 0 8px 8px 0;
        }

        .paper-content .theorem-title {
            font-family: 'Inter', sans-serif;
            font-weight: 600;
            margin-bottom: 8px;
        }

        .paper-content .proof {
            background: var(--surface-2);
            padding: 16px 20px;
            margin: 16px 0;
            border-radius: 8px;
            font-size: 1rem;
        }

        .paper-content .proof::before {
            content: "Proof. ";
            font-style: italic;
        }

        .paper-content .proof::after {
            content: " \25A1";
        }

        .paper-content .remark {
            background: var(--surface);
            border-left: 4px solid var(--warning);
            padding: 16px 20px;
            margin: 24px 0;
            border-radius: 0 8px 8px 0;
        }

        .paper-content .abstract {
            background: var(--surface);
            padding: 32px;
            border-radius: 12px;
            margin-bottom: 48px;
            border: 1px solid var(--border);
        }

        .paper-content .abstract h2 {
            margin-top: 0;
            font-size: 1.2rem;
        }

        .paper-content .keywords {
            margin-top: 24px;
            font-size: 0.95rem;
            color: var(--text-muted);
        }

        .section-divider {
            height: 1px;
            background: var(--border);
            margin: 64px 0;
        }

        /* Tab navigation for paper */
        .tabs {
            display: flex;
            gap: 8px;
            margin-bottom: 32px;
            flex-wrap: wrap;
        }

        .tab-btn {
            background: var(--surface);
            border: 1px solid var(--border);
            color: var(--text-muted);
            padding: 10px 20px;
            border-radius: 8px;
            cursor: pointer;
            font-family: 'Inter', sans-serif;
            font-size: 0.9rem;
            transition: all 0.2s;
        }

        .tab-btn:hover {
            border-color: var(--accent);
            color: var(--text);
        }

        .tab-btn.active {
            background: var(--accent);
            border-color: var(--accent);
            color: white;
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        /* Footer */
        footer {
            padding: 40px 0;
            text-align: center;
            color: var(--text-muted);
            font-size: 0.875rem;
        }

        footer a {
            color: var(--accent);
            text-decoration: none;
        }

        footer a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <nav>
        <div class="container">
            <span class="logo">Twin Prime Selection Bias</span>
            <ul>
                <li><a href="#results" class="active">Results</a></li>
                <li><a href="#paper">Paper</a></li>
                <li><a href="https://github.com/bmdragos/twin-prime-selection-bias">GitHub</a></li>
            </ul>
        </div>
    </nav>

    <div id="results">
        <div class="hero">
            <div class="container">
                <h1>Twin Prime Selection Bias</h1>
                <p class="subtitle">
                    Composites adjacent to primes have systematically higher factor counts
                    than composites in purely composite pairs.
                </p>
                <div class="stat-box">
                    <div class="stat-value">+2.93%</div>
                    <div class="stat-label">Selection Bias in Omega</div>
                </div>
            </div>
        </div>

        <section>
            <div class="container">
                <h2>The Core Finding</h2>
                <p class="section-desc">
                    For twin prime candidates (6k-1, 6k+1), we classify each pair by primality state.
                    The composite member of a PC pair has ~2.93% more distinct prime factors than composites in CC pairs.
                </p>

                <div class="grid-2">
                    <div class="card">
                        <h3><span class="icon"></span> Twin Prime Pairs</h3>
                        <p style="color: var(--text-muted); margin-bottom: 12px;">
                            All primes &gt; 3 are of form 6k&plusmn;1. We examine pairs (a, b) = (6k-1, 6k+1):
                        </p>
                        <ul style="list-style: none; margin-top: 12px;">
                            <li><span class="state-pp">PP</span> &mdash; Both prime (twin primes!)</li>
                            <li><span class="state-pc">PC</span> &mdash; a prime, b composite</li>
                            <li><span class="state-cp">CP</span> &mdash; a composite, b prime</li>
                            <li><span class="state-cc">CC</span> &mdash; Both composite</li>
                        </ul>
                    </div>

                    <div class="card">
                        <h3><span class="icon"></span> Selection Bias</h3>
                        <p style="color: var(--text-muted);">
                            Omega (&omega;) counts distinct prime factors. We find:
                        </p>
                        <div class="math-block">
                            $\omega(\text{PC composite}) > \omega(\text{CC composite})$
                        </div>
                        <p style="color: var(--text-muted);">
                            Being "selected" by adjacency to a prime correlates with having
                            more prime factors. The bias is stable across 10<sup>7</sup> to 10<sup>9</sup> pairs.
                        </p>
                    </div>
                </div>

                <div class="card" style="margin-top: 24px; border-left: 4px solid var(--accent);">
                    <h3>The Mechanism: Mutual Exclusivity</h3>
                    <p style="color: var(--text-muted); margin-bottom: 12px;">
                        For any prime $p \geq 5$, the residue classes where $p \mid a$ and $p \mid b$ are <strong>disjoint</strong>.
                        If both held, then $p \mid (b - a) = 2$, which is impossible for $p \geq 5$.
                    </p>
                    <p style="color: var(--text-muted); margin-bottom: 12px;">
                        This means: conditioning on "$a$ is prime" (so $p \nmid a$ for all $p$) <em>boosts</em> the probability
                        that $p \mid b$ from $1/p$ to $1/(p-1)$. Sum the increments:
                    </p>
                    <div class="math-block">
                        $\sum_{p \geq 5} \frac{1}{p(p-1)} = 0.1065 \approx \text{observed } 0.107$
                    </div>
                </div>
            </div>
        </section>

        <!-- EVIDENCE: The bias is real -->
        <section>
            <div class="container">
                <h2>Bias Stability Across Scale</h2>
                <p class="section-desc">
                    The selection bias remains remarkably stable as we increase K from 10 million to 1 billion pairs.
                </p>
                <div class="chart-container">
                    <div id="chart-stability" class="chart"></div>
                </div>
            </div>
        </section>

        <section>
            <div class="container">
                <h2>Why It Stabilizes: Convergence of the Sum</h2>
                <p class="section-desc">
                    The per-prime increments $1/[p(p-1)]$ form a convergent series. Small primes dominate:
                    the first 5 primes contribute 87% of the total. Adding more pairs doesn't change the sum.
                </p>
                <div class="chart-container">
                    <div id="chart-convergence" class="chart"></div>
                </div>
            </div>
        </section>

        <section>
            <div class="container">
                <h2>Window Stability</h2>
                <p class="section-desc">
                    Critical test: is the bias stable in the tail, not just in prefix averages?
                    The bias is <em>slightly higher</em> in the tail, ruling out drift.
                </p>
                <div class="chart-container">
                    <div id="chart-windows" class="chart"></div>
                </div>
            </div>
        </section>

        <!-- THE PAYOFF: Mechanism is correct -->
        <section style="background: linear-gradient(180deg, rgba(34, 197, 94, 0.05) 0%, transparent 100%);">
            <div class="container">
                <h2>The Payoff: Generalization Across Patterns</h2>
                <p class="section-desc">
                    If the mechanism is correct, it should work for <em>any</em> admissible prime pair&mdash;not just twins.
                    Three patterns, three predictions, all matching within 1%.
                </p>
                <div class="chart-container">
                    <div id="chart-generalization" class="chart"></div>
                </div>
                <div class="grid-2" style="margin-top: 24px;">
                    <div class="card">
                        <h3>Sophie Germain Pairs $(n, 2n+1)$</h3>
                        <p style="color: var(--text-muted); margin-bottom: 12px;">
                            If $q \mid n$ and $q \mid (2n+1)$, then $q \mid 1$&mdash;impossible. Mutual exclusivity holds for all odd primes.
                        </p>
                        <div class="math-block">
                            $\sum_{q \geq 3} \frac{1}{q(q-1)} = 0.273$
                        </div>
                        <p style="color: var(--text-muted); font-size: 0.9rem;">
                            Sum starts at $q=3$ because $2 \nmid (2n+1)$ for any $n$. Verified at $N=10^9$ (odd $n$ only).
                        </p>
                    </div>
                    <div class="card">
                        <h3>Cousin Primes $(n, n+4)$</h3>
                        <p style="color: var(--text-muted); margin-bottom: 12px;">
                            For $6k \pm 1$ candidates: $3 \mid (n+4)$ depends on residue class, not primality&mdash;so $p=3$ contributes zero to the difference.
                        </p>
                        <div class="math-block">
                            $\sum_{p \geq 5} \frac{1}{p(p-1)} = 0.1065$
                        </div>
                        <p style="color: var(--text-muted); font-size: 0.9rem;">
                            Achieves <strong>0.1%</strong> agreement&mdash;better than twin primes!
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <!-- DEEPER ANALYSIS -->
        <section>
            <div class="container">
                <h2>&omega; Decomposition: Small vs Large Primes</h2>
                <p class="section-desc">
                    The full $\omega = \omega_{\text{small}} + \mathbf{1}\{\text{has large prime factor}\}$ decomposes into
                    competing effects. Large prime cofactors partially cancel the small-prime bias.
                </p>
                <div class="chart-container">
                    <div id="chart-decomposition" class="chart"></div>
                </div>
                <div class="card" style="margin-top: 24px;">
                    <h3>Smoothness Interpretation</h3>
                    <p style="color: var(--text-muted);">
                        PC composites are ~1.2 percentage points more likely to be $\sqrt{N}$-smooth (32.4% vs 31.2%).
                        More small prime factors &rarr; less "room" for a large cofactor. The CC smoothness rate of
                        31.2% is close to the Dickman function $\rho(2) = 1 - \ln 2 \approx 30.7\%$, the "ambient" rate
                        for random integers.
                    </p>
                </div>
            </div>
        </section>

        <!-- REFERENCE DATA -->
        <section>
            <div class="container">
                <h2>Reference Data: Mean Omega by State</h2>
                <p class="section-desc">
                    Comparing mean &omega; across states at K=10<sup>9</sup>. PP pairs have &omega;=1 by definition (primes).
                </p>
                <div class="chart-container">
                    <div id="chart-omega" class="chart"></div>
                </div>

                <div class="card" style="margin-top: 24px;">
                    <h3>Results at K = 10<sup>9</sup></h3>
                    <table>
                        <thead>
                            <tr>
                                <th>State</th>
                                <th>Count</th>
                                <th>Fraction</th>
                                <th>Mean &omega;(a)</th>
                                <th>Mean &omega;(b)</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="state-pp">PP</td>
                                <td class="mono">17,244,408</td>
                                <td class="mono">1.72%</td>
                                <td class="mono">1.0000</td>
                                <td class="mono">1.0000</td>
                            </tr>
                            <tr>
                                <td class="state-pc">PC</td>
                                <td class="mono">122,531,277</td>
                                <td class="mono">12.25%</td>
                                <td class="mono">1.0000</td>
                                <td class="mono">2.9067</td>
                            </tr>
                            <tr>
                                <td class="state-cp">CP</td>
                                <td class="mono">122,525,274</td>
                                <td class="mono">12.25%</td>
                                <td class="mono">2.9068</td>
                                <td class="mono">1.0000</td>
                            </tr>
                            <tr>
                                <td class="state-cc">CC</td>
                                <td class="mono">737,699,041</td>
                                <td class="mono">73.77%</td>
                                <td class="mono">2.8239</td>
                                <td class="mono">2.8239</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </section>

        <section>
            <div class="container">
                <h2>Baseline Comparisons</h2>
                <p class="section-desc">
                    The effect size depends on your baseline: +2.93% vs CC composites, +2.50% vs unconditional composites.
                </p>
                <div class="chart-container">
                    <div id="chart-baselines" class="chart"></div>
                </div>
            </div>
        </section>

        <!-- SUPPLEMENTARY -->
        <section>
            <div class="container">
                <h2>State Distribution</h2>
                <p class="section-desc">
                    As K increases, the fraction of prime-containing pairs decreases (primes thin out per the prime number theorem).
                </p>
                <div class="chart-container">
                    <div id="chart-distribution" class="chart"></div>
                </div>
            </div>
        </section>
    </div>

    <!-- Paper Section -->
    <div id="paper" class="paper-section">
        <div class="paper-container">
            <h1 style="font-size: 2rem; text-align: center; margin-bottom: 8px;">A Selection Bias in the Prime Factors of Twin Prime Candidates</h1>
            <p style="text-align: center; color: var(--text-muted); margin-bottom: 48px;">Full Paper with LaTeX Equations</p>

            <div class="tabs">
                <button class="tab-btn active" data-tab="abstract">Abstract</button>
                <button class="tab-btn" data-tab="intro">1. Introduction</button>
                <button class="tab-btn" data-tab="empirical">2. Empirical</button>
                <button class="tab-btn" data-tab="heuristic">3. Heuristic</button>
                <button class="tab-btn" data-tab="transfer">4. Residue-Class</button>
                <button class="tab-btn" data-tab="discussion">5. Discussion</button>
            </div>

            <!-- Abstract -->
            <div id="abstract" class="tab-content active">
                <div class="paper-content">
                    <div class="abstract">
                        <h2>Abstract</h2>
                        <p>
                            We document a selection bias in the arithmetic structure of composite numbers adjacent to primes.
                            Among pairs $(6k-1, 6k+1)$ classified by the primality of each member, the composite element of a
                            "prime-composite" pair has approximately 3% more distinct prime factors than composites in
                            "composite-composite" pairs.
                        </p>
                        <p>
                            At $K = 10^9$ pairs, the mean $\omega$ (distinct prime factors) for PC composites is $2.907$ versus
                            $2.824$ for CC composites, a relative uplift of $2.93\%$. This bias is stable across two orders of
                            magnitude in $K$ ($10^7$ to $10^9$) and persists (slightly elevated) in tail windows, ruling out transient or drifting artifacts.
                        </p>
                        <p>
                            We derive the bias from first principles. For each prime $p \geq 5$, the congruence classes
                            $k \pmod p$ where $p \mid (6k-1)$ and $p \mid (6k+1)$ are disjoint. This mutual exclusivity implies
                            that conditioning on "$a$ is prime" boosts the probability that $p \mid b$ from $1/p$ to $1/(p-1)$.
                            Summing the per-prime increments yields a convergent sum
                            $$\sum_{p \geq 5} \frac{1}{p(p-1)} = 0.1065$$
                        </p>
                        <p>
                            When compared to the correctly-aligned conditional expectation
                            $\mathbb{E}[\omega(b) \mid a \text{ prime}] - \mathbb{E}[\omega(b) \mid a \text{ composite}] = 0.107$,
                            the heuristic matches empirical data to within $1\%$. The PC-vs-CC composite difference of $0.0828$
                            is smaller because it further conditions on "$b$ composite," which modifies expectations through
                            elementary conditioning algebra.
                        </p>
                        <div class="keywords">
                            <strong>Keywords:</strong> twin primes, prime factors, selection bias, Hardy-Littlewood, sieve methods<br>
                            <strong>MSC 2020:</strong> 11N05, 11A41, 11Y11
                        </div>
                    </div>
                </div>
            </div>

            <!-- Section 1: Introduction -->
            <div id="intro" class="tab-content">
                <div class="paper-content">
                    <h1>1. Introduction</h1>

                    <h2>1.1 Motivation</h2>
                    <p>
                        Consider the integers of the form $6k \pm 1$ for positive integers $k$. Every prime greater than 3
                        belongs to one of these two residue classes modulo 6, and the pairs $(6k-1, 6k+1)$ exhaust all twin
                        prime candidates beyond $(3, 5)$.
                    </p>
                    <p>
                        For each such pair, we may ask: if exactly one member is prime, what can we say about the arithmetic
                        structure of the composite partner?
                    </p>
                    <p>
                        Naively, one might expect the composite to be "generic"&mdash;statistically indistinguishable from a
                        random composite of similar size. This paper shows that this expectation is false. Composites adjacent
                        to primes have systematically <em>more</em> distinct prime factors than composites in pairs where both
                        members are composite.
                    </p>

                    <h2>1.2 Main Results</h2>
                    <p>
                        Let $\omega(n)$ denote the number of distinct prime factors of $n$. We classify pairs
                        $(a, b) = (6k-1, 6k+1)$ into four states:
                    </p>
                    <ul>
                        <li><strong>PP:</strong> Both $a$ and $b$ are prime (twin primes)</li>
                        <li><strong>PC:</strong> $a$ is prime, $b$ is composite</li>
                        <li><strong>CP:</strong> $a$ is composite, $b$ is prime</li>
                        <li><strong>CC:</strong> Both are composite</li>
                    </ul>

                    <div class="theorem">
                        <div class="theorem-title">Observation 1.1 (Empirical)</div>
                        At $K = 10^9$ pairs:
                        $$\mathbb{E}[\omega(b) \mid \text{PC}] - \mathbb{E}[\omega(b) \mid \text{CC}] = 0.0828 \pm 0.0001$$
                        corresponding to a relative uplift of $2.93\%$.
                    </div>

                    <div class="theorem">
                        <div class="theorem-title">Observation 1.2 (Stability)</div>
                        The selection bias is stable:
                        <ul>
                            <li>Across scale: $2.96\%, 2.94\%, 2.93\%$ at $K = 10^7, 10^8, 10^9$</li>
                            <li>Within runs: $3.00\%$ in the tail $[0.9K, K]$ vs $2.93\%$ in the full sample</li>
                        </ul>
                    </div>

                    <div class="theorem">
                        <div class="theorem-title">Proposition 1.3 (Heuristic)</div>
                        The bias is explained by mutual exclusivity of divisibility. For each prime $p \geq 5$, conditioning
                        on $p \nmid a$ boosts $\mathbb{P}(p \mid b)$ from $1/p$ to $1/(p-1)$. Summing the per-prime increments:
                        $$\sum_{p \geq 5} \frac{1}{p(p-1)} = 0.1065$$
                        This predicts $\mathbb{E}[\omega(b) \mid a \text{ prime}] - \mathbb{E}[\omega(b) \mid a \text{ composite}]$.
                        Empirically, this difference is $0.107$, matching the prediction to within $1\%$.
                    </div>

                    <h2>1.3 Context</h2>
                    <p>
                        The Hardy-Littlewood conjecture and its refinements predict the density of prime pairs, but the
                        <em>internal structure</em> of near-prime pairs has received less attention. Our result complements
                        density predictions with a structural observation: the "near-miss" composites adjacent to primes are
                        arithmetically distinguished.
                    </p>

                    <h2>1.4 Organization</h2>
                    <ul>
                        <li><strong>Section 2</strong> presents the empirical observations: state distributions, selection bias,
                            and stability across scale and within runs.</li>
                        <li><strong>Section 3</strong> derives the bias from first principles via the mutual exclusivity mechanism.</li>
                        <li><strong>Section 4</strong> formalizes the correlations using a transfer-matrix model.</li>
                        <li><strong>Section 5</strong> discusses implications, open questions, and why the result is
                            "not surprising, but still useful."</li>
                    </ul>
                </div>
            </div>

            <!-- Section 2: Empirical -->
            <div id="empirical" class="tab-content">
                <div class="paper-content">
                    <h1>2. Empirical Observation</h1>

                    <h2>2.1 Setup and Definitions</h2>
                    <p>We consider pairs of integers of the form</p>
                    $$(a, b) = (6k - 1, 6k + 1)$$
                    <p>
                        for positive integers $k$. Every prime greater than 3 lies in one of these two residue classes modulo 6,
                        so these pairs exhaust all twin-prime candidates beyond the pair $(3, 5)$.
                    </p>
                    <p>
                        For each pair, we classify the <strong>state</strong> according to the primality of each component.
                        Our primary observable is $\omega(n)$, the number of <strong>distinct</strong> prime factors of $n$.
                        For prime $n$, we have $\omega(n) = 1$.
                    </p>

                    <h2>2.2 State Distribution</h2>
                    <p>At $K = 10^9$ pairs, the observed state frequencies are:</p>
                    <table>
                        <thead>
                            <tr><th>State</th><th>Count</th><th>Fraction</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>PP</td><td class="mono">17,244,408</td><td class="mono">1.72%</td></tr>
                            <tr><td>PC</td><td class="mono">122,531,277</td><td class="mono">12.25%</td></tr>
                            <tr><td>CP</td><td class="mono">122,525,274</td><td class="mono">12.25%</td></tr>
                            <tr><td>CC</td><td class="mono">737,699,041</td><td class="mono">73.77%</td></tr>
                        </tbody>
                    </table>

                    <h2>2.3 The Selection Bias</h2>
                    <p>Our central empirical finding concerns the mean value of $\omega$ for the composite member of PC and CP pairs compared to CC pairs.</p>

                    <div class="theorem">
                        <div class="theorem-title">Main Result</div>
                        At $K = 10^9$:
                        <table>
                            <thead>
                                <tr><th>Population</th><th>Mean $\omega$</th><th>Sample size</th></tr>
                            </thead>
                            <tbody>
                                <tr><td>PC composite (the $b$ in PC)</td><td class="mono">2.9067</td><td class="mono">122,531,277</td></tr>
                                <tr><td>CP composite (the $a$ in CP)</td><td class="mono">2.9068</td><td class="mono">122,525,274</td></tr>
                                <tr><td>CC composite (either $a$ or $b$)</td><td class="mono">2.8239</td><td class="mono">737,699,041</td></tr>
                                <tr><td>Unconditional composite at $6k+1$</td><td class="mono">2.8357</td><td class="mono">860,230,318</td></tr>
                            </tbody>
                        </table>
                    </div>

                    <p>The <strong>selection bias</strong> is defined as the relative uplift:</p>
                    $$\text{Bias} = \frac{\mathbb{E}[\omega \mid \text{PC}] - \mathbb{E}[\omega \mid \text{CC}]}{\mathbb{E}[\omega \mid \text{CC}]} = \frac{2.9067 - 2.8239}{2.8239} = 2.93\%$$

                    <h2>2.4 Stability Across Scale</h2>
                    <p>A natural concern is whether the observed bias is a finite-size artifact. We tested this by computing the bias at three scales:</p>
                    <table>
                        <thead>
                            <tr><th>$K$</th><th>Bias (PC vs CC)</th></tr>
                        </thead>
                        <tbody>
                            <tr><td class="mono">$10^7$</td><td class="mono">2.956%</td></tr>
                            <tr><td class="mono">$10^8$</td><td class="mono">2.940%</td></tr>
                            <tr><td class="mono">$10^9$</td><td class="mono">2.933%</td></tr>
                        </tbody>
                    </table>
                    <p>The bias is remarkably stable, decreasing by only 0.02 percentage points per decade of $K$.</p>

                    <h2>2.5 Tail-Window Stability</h2>
                    <p>A more stringent test asks whether the bias is stable <strong>within</strong> a run:</p>
                    <table>
                        <thead>
                            <tr><th>Window</th><th>Bias (PC vs CC)</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>Full $[1, K]$</td><td class="mono">2.93%</td></tr>
                            <tr><td>Second half $[K/2, K]$</td><td class="mono">3.00%</td></tr>
                            <tr><td>Last 10% $[0.9K, K]$</td><td class="mono">3.00%</td></tr>
                            <tr><td>Last 1% $[0.99K, K]$</td><td class="mono">2.99%</td></tr>
                        </tbody>
                    </table>
                    <p>The bias in the tail is <strong>slightly higher</strong> than in the full sample, ruling out the possibility of a slowly drifting effect.</p>

                    <h2>2.6 Baseline Consistency Check</h2>
                    <p>We verified internal consistency by checking that the unconditional mean can be reconstructed as a mixture of conditional means:</p>
                    $$\mathbb{E}[\omega \mid b \text{ composite}] = \pi \cdot \mathbb{E}[\omega \mid \text{PC}] + (1 - \pi) \cdot \mathbb{E}[\omega \mid \text{CC}]$$
                    $$= 0.14 \times 2.9067 + 0.86 \times 2.8239 = 2.8354$$
                    <p>The observed unconditional mean is $2.8357$, matching to four decimal places.</p>

                    <h2>2.7 Decomposition of the Bias</h2>
                    <p>The total bias of $2.93\%$ conflates two distinct mechanisms:</p>
                    $$\mu_{\text{PC}} - \mu_{\text{CC}} = \underbrace{(\mu_{\text{PC}} - \mu_{\text{uncond}})}_{\text{PC uplift}} + \underbrace{(\mu_{\text{uncond}} - \mu_{\text{CC}})}_{\text{CC suppression}}$$

                    <table>
                        <thead>
                            <tr><th>Component</th><th>Value</th><th>Fraction</th></tr>
                        </thead>
                        <tbody>
                            <tr><td>PC uplift</td><td class="mono">$2.9067 - 2.8357 = 0.0710$</td><td class="mono">86%</td></tr>
                            <tr><td>CC suppression</td><td class="mono">$2.8357 - 2.8239 = 0.0118$</td><td class="mono">14%</td></tr>
                            <tr><td><strong>Total</strong></td><td class="mono">$0.0828$</td><td class="mono">100%</td></tr>
                        </tbody>
                    </table>

                    <p><strong>Interpretation:</strong> The dominant effect (86%) is PC uplift&mdash;primes push factors onto neighbors. The secondary effect (14%) is CC suppression&mdash;composites pull factors away from neighbors.</p>
                </div>
            </div>

            <!-- Section 3: Heuristic -->
            <div id="heuristic" class="tab-content">
                <div class="paper-content">
                    <h1>3. First-Principles Heuristic</h1>

                    <h2>3.1 The Local Mechanism</h2>
                    <p>
                        The selection bias arises from a simple arithmetic identity. For a prime $p \geq 5$ and the pair
                        $(a, b) = (6k-1, 6k+1)$:
                    </p>
                    <ul>
                        <li>Exactly one residue class $k \pmod{p}$ satisfies $p \mid a$.</li>
                        <li>Exactly one residue class $k \pmod{p}$ satisfies $p \mid b$.</li>
                        <li>These two classes are <strong>disjoint</strong>: if both held, then $p \mid (b - a) = 2$,
                            which is impossible for $p \geq 5$.</li>
                    </ul>
                    <p>
                        This mutual exclusivity is the engine of the bias. It implies that the events "$p \mid a$" and
                        "$p \mid b$" are negatively correlated.
                    </p>

                    <div class="card" style="margin: 24px 0; font-family: 'JetBrains Mono', monospace; font-size: 0.85rem;">
                        <strong>Figure: Mutual Exclusivity at $p = 5$</strong>
                        <pre style="margin-top: 12px; overflow-x: auto;">
k mod 5:    0       1       2       3       4
            |       |       |       |       |
  5|a?      x       ✓       x       x       x     (6k ≡ 1 mod 5 when k ≡ 1)
  5|b?      x       x       ✓       x       x     (6k ≡ -1 mod 5 when k ≡ 2)
                    ↑       ↑
              "forbidden"  "forbidden"
               for b       for a</pre>
                        <p style="margin-top: 12px; font-family: 'Source Serif 4', serif; font-size: 1rem;">
                            The classes where $5 \mid a$ and $5 \mid b$ are <strong>disjoint</strong>.
                            Conditioning on "$a$ is prime" excludes $k \equiv 1$, leaving 4 classes&mdash;one of which has $5 \mid b$.
                            Thus $\mathbb{P}(5 \mid b \mid 5 \nmid a) = 1/4$, not $1/5$.
                        </p>
                    </div>

                    <div class="theorem">
                        <div class="theorem-title">Proposition 3.1</div>
                        For any prime $p \geq 5$,
                        $$\mathbb{P}(p \mid b \mid p \nmid a) = \frac{1}{p-1}$$
                    </div>

                    <div class="proof">
                        Among the $p$ residue classes modulo $p$, exactly one has $p \mid b$. Conditioning on $p \nmid a$
                        removes one class (the unique class with $p \mid a$), leaving $p - 1$ equally likely classes.
                        Exactly one of these has $p \mid b$.
                    </div>

                    <p>The unconditional probability $\mathbb{P}(p \mid b) = 1/p$ is boosted to $1/(p-1)$ upon conditioning. The per-prime increment is:</p>
                    $$\delta_p = \frac{1}{p-1} - \frac{1}{p} = \frac{1}{p(p-1)}$$

                    <h2>3.2 The Independent-Prime Sum</h2>
                    <p>
                        We now make a heuristic leap: assume that the primality of $a$ is determined independently by each
                        prime $p$, and that the increments $\delta_p$ contribute additively to the expected number of
                        distinct prime factors of $b$.
                    </p>
                    <p>Under the independent-prime heuristic:</p>
                    $$\mathbb{E}[\omega(b) \mid a \text{ prime}] - \mathbb{E}[\omega(b)] \approx \sum_{p \geq 5} \delta_p = \sum_{p \geq 5} \frac{1}{p(p-1)}$$

                    <p>This sum converges:</p>
                    $$\sum_{p \geq 5} \frac{1}{p(p-1)} = 0.1065\ldots$$

                    <p>The first few terms dominate:</p>
                    <table>
                        <thead>
                            <tr><th>$p$</th><th>$1/[p(p-1)]$</th><th>Cumulative</th></tr>
                        </thead>
                        <tbody>
                            <tr><td class="mono">5</td><td class="mono">0.0500</td><td class="mono">0.0500</td></tr>
                            <tr><td class="mono">7</td><td class="mono">0.0238</td><td class="mono">0.0738</td></tr>
                            <tr><td class="mono">11</td><td class="mono">0.0091</td><td class="mono">0.0829</td></tr>
                            <tr><td class="mono">13</td><td class="mono">0.0064</td><td class="mono">0.0893</td></tr>
                            <tr><td class="mono">17</td><td class="mono">0.0037</td><td class="mono">0.0930</td></tr>
                        </tbody>
                    </table>

                    <div class="remark">
                        <strong>Remark.</strong> The convergence of this sum explains why the bias stabilizes rather than
                        growing or shrinking with $K$. Each prime contributes a fixed increment to the absolute shift
                        $\Delta\omega$, and almost all of this contribution comes from small primes.
                    </div>

                    <h2>3.3 The Correctly-Aligned Comparison</h2>
                    <p>The heuristic predicts $\mathbb{E}[\omega(b) \mid a \text{ prime}] - \mathbb{E}[\omega(b) \mid a \text{ composite}]$.
                    To test this, we compute the <strong>full</strong> conditional expectations&mdash;including cases where $b$ is prime.</p>

                    <p><strong>Computing $\mathbb{E}[\omega(b) \mid a \text{ prime}]$:</strong></p>
                    $$\mathbb{E}[\omega(b) \mid a \text{ prime}] = 0.1234 \times 1 + 0.8766 \times 2.9067 = 2.671$$

                    <p><strong>Computing $\mathbb{E}[\omega(b) \mid a \text{ composite}]$:</strong></p>
                    $$\mathbb{E}[\omega(b) \mid a \text{ composite}] = 0.1424 \times 1 + 0.8576 \times 2.8239 = 2.564$$

                    <p><strong>The comparison:</strong> The empirical difference is:</p>
                    $$\mathbb{E}[\omega(b) \mid a \text{ prime}] - \mathbb{E}[\omega(b) \mid a \text{ composite}] = 2.671 - 2.564 = 0.107$$

                    <p>This matches the heuristic prediction of $0.1065$ to within $1\%$:</p>
                    $$\frac{0.107}{0.1065} \approx 1.00$$

                    <div class="remark">
                        <strong>Key result:</strong> The independent-prime heuristic accounts for essentially the entire
                        observed effect when applied to the correctly-aligned conditional expectations.
                    </div>

                    <h2>3.4 The PC-vs-CC Comparison as a Derived Quantity</h2>
                    <p>The composite-only comparison $\mathbb{E}[\omega(b) \mid \text{PC}] - \mathbb{E}[\omega(b) \mid \text{CC}] = 0.0828$
                    is smaller than the full conditional difference of $0.107$ because it excludes the prime cases.
                    This difference arises from elementary conditioning algebra, not from any failure of the heuristic.</p>

                    <h2>3.5 Summary</h2>
                    <p>The selection bias admits a clean first-principles explanation:</p>
                    <ol>
                        <li><strong>Exact:</strong> For each $p \geq 5$, conditioning on $p \nmid a$ boosts
                            $\mathbb{P}(p \mid b)$ from $1/p$ to $1/(p-1)$.</li>
                        <li><strong>Heuristic:</strong> Summing the per-prime increments gives
                            $\sum 1/[p(p-1)] = 0.1065$.</li>
                        <li><strong>Empirical verification:</strong> The correctly-aligned conditional difference
                            $\mathbb{E}[\omega(b) \mid a \text{ prime}] - \mathbb{E}[\omega(b) \mid a \text{ composite}] = 0.107$
                            matches the heuristic to within $1\%$.</li>
                        <li><strong>Derived quantity:</strong> The PC-vs-CC comparison ($0.0828$) is smaller because
                            it excludes prime-$b$ cases.</li>
                    </ol>
                </div>
            </div>

            <!-- Section 4: Residue-Class Model -->
            <div id="transfer" class="tab-content">
                <div class="paper-content">
                    <h1>4. Residue-Class Model and Inclusion-Exclusion</h1>

                    <h2>4.1 Motivation</h2>
                    <p>
                        Section 3 established that the independent-prime heuristic, when applied to correctly-aligned conditional expectations,
                        predicts the observed effect with high accuracy. The purpose of this section is to provide a systematic framework
                        for computing conditional expectations under various conditioning schemes.
                    </p>
                    <p>
                        We formulate a residue-class model using inclusion-exclusion over joint divisibility states.
                        It serves as a bookkeeping device that clarifies how different conditioning choices transform expectations.
                    </p>

                    <h2>4.2 State Space</h2>
                    <p>
                        Fix a finite set $\mathcal{P} = \{p_1, \ldots, p_r\}$ of primes with $p_i \geq 5$. Define the
                        <strong>state</strong> of $k$ to be the pair $(\sigma_a, \sigma_b)$ where $\sigma_a, \sigma_b \subseteq \mathcal{P}$
                        are the sets of primes dividing $a$ and $b$ respectively.
                    </p>
                    <p>
                        By mutual exclusivity, $\sigma_a \cap \sigma_b = \emptyset$. The state space has size $3^r$
                        (each prime is in $\sigma_a$, in $\sigma_b$, or in neither).
                    </p>

                    <h2>4.3 Stationary Distribution</h2>
                    <p>The stationary probability of state $(\sigma_a, \sigma_b)$ is:</p>
                    $$\pi(\sigma_a, \sigma_b) = \prod_{p \in \sigma_a} \frac{1}{p} \cdot \prod_{p \in \sigma_b} \frac{1}{p} \cdot \prod_{p \notin \sigma_a \cup \sigma_b} \frac{p-2}{p}$$

                    <h2>4.4 Example: $\mathcal{P} = \{5\}$</h2>
                    <p>The three states are:</p>
                    <ul>
                        <li>$(5 \mid a, 5 \nmid b)$: probability $1/5$</li>
                        <li>$(5 \nmid a, 5 \mid b)$: probability $1/5$</li>
                        <li>$(5 \nmid a, 5 \nmid b)$: probability $3/5$</li>
                    </ul>
                    <p>This recovers the mutual exclusivity: $\mathbb{P}(5 \mid b \mid 5 \nmid a) = (1/5) / (4/5) = 1/4 = 1/(5-1)$.</p>

                    <h2>4.5 Conditioning Transformations</h2>
                    <p>The residue-class model clarifies why different conditioning schemes yield different $\omega$-expectations:</p>
                    <ul>
                        <li><strong>Primary conditional:</strong> For $\mathbb{E}[|\sigma_b| \mid \sigma_a = \emptyset]$,
                            the heuristic sum $\sum 1/[p(p-1)]$ is exact as $|\mathcal{P}| \to \infty$.</li>
                        <li><strong>Secondary conditional:</strong> For PC-vs-CC, additional conditioning on "$b$ composite"
                            modifies expectations&mdash;explaining why the difference is smaller.</li>
                    </ul>

                    <h2>4.6 Connection to Sieve Theory</h2>
                    <p>The residue-class model is an application of inclusion-exclusion over the sieve dimension:</p>
                    <ol>
                        <li><strong>Sieve weights:</strong> The measure $\pi(\sigma_a, \sigma_b)$ corresponds to sieve weights on residue classes.</li>
                        <li><strong>Local constraint:</strong> The mutual exclusivity constraint ($\sigma_a \cap \sigma_b = \emptyset$) reduces the state space.</li>
                        <li><strong>Product structure:</strong> The factorization enables exact computation via inclusion-exclusion.</li>
                    </ol>
                    <p>The model provides exact conditional expectations for any finite $\mathcal{P}$, useful for understanding conditioning transformations.</p>

                    <h2>4.7 Interpretation</h2>
                    <p>The residue-class model provides:</p>
                    <ol>
                        <li><strong>A proof that correlations reduce the bias.</strong> The independent-prime heuristic
                            corresponds to replacing the joint distribution with a product measure.</li>
                        <li><strong>A computable correction.</strong> For any finite $\mathcal{P}$, the bias can be
                            computed exactly from the transfer matrix.</li>
                        <li><strong>A bridge to analytic methods.</strong> The structure suggests connections to sieve
                            theory, where similar product-over-primes formulas appear.</li>
                    </ol>
                </div>
            </div>

            <!-- Section 5: Discussion -->
            <div id="discussion" class="tab-content">
                <div class="paper-content">
                    <h1>5. Discussion</h1>

                    <h2>5.1 Why This Is Not Surprising</h2>
                    <p>
                        The selection bias we observe is, in hindsight, predictable from first principles. The mutual
                        exclusivity of divisibility is an elementary fact about modular arithmetic. A skeptical reader
                        might reasonably ask: <em>what is new here?</em>
                    </p>
                    <p>We offer three responses:</p>
                    <ul>
                        <li><strong>The quantitative match is nontrivial.</strong> The convergent sum
                            $\sum 1/[p(p-1)] = 0.1065$ predicts the correctly-aligned conditional difference to within $1\%$.
                            This near-exact agreement was not guaranteed a priori.</li>
                        <li><strong>The stability requires explanation.</strong> The bias persists unchanged across
                            five orders of magnitude in $K$.</li>
                        <li><strong>The baseline ambiguity is instructive.</strong> The effect size changes from 2.93%
                            (vs CC) to 2.50% (vs unconditional) depending on the baseline.</li>
                    </ul>

                    <h2>5.2 Implications for Twin Prime Heuristics</h2>
                    <p>The Hardy-Littlewood conjecture predicts:</p>
                    $$\pi_2(N) \sim 2C_2 \frac{N}{(\log N)^2}$$
                    <p>
                        where $C_2 = \prod_{p \geq 3} (1 - 1/(p-1)^2) \approx 0.66$ is the twin prime constant. The same
                        mutual exclusivity that drives the selection bias also appears in this constant.
                    </p>

                    <h2>5.3 Open Questions</h2>
                    <ol>
                        <li><strong>Is the PC-vs-CC bias derivable from Hardy-Littlewood asymptotics?</strong> The full
                            conditional difference of $0.1074$ follows from the convergent sum plus equidistribution.
                            The PC-vs-CC difference additionally depends on the PP/PC/CP/CC proportions. Experts in
                            sieve theory may already know this derivation.</li>
                        <li><strong>Does the bias extend to other prime patterns?</strong>
                            <p><em>Sophie Germain pairs $(n, 2n+1)$:</em> If $q \mid n$ and $q \mid (2n+1)$, then $q \mid 1$—impossible.
                            Predicted shift: $\sum_{q \geq 3} 1/[q(q-1)] = 0.273$ (sum starts at $q=3$ since $2 \nmid (2n+1)$ for any $n$).
                            At $N = 10^9$ among odd $n$: empirical difference $= 0.272$, matching to <strong>0.4%</strong>.</p>
                            <p><em>Cousin primes $(n, n+4)$:</em> For $6k \pm 1$ candidates, $3 \mid (n+4)$ depends on residue class, not primality—so $p=3$ contributes zero to the difference.
                            Predicted shift $= 0.1065$. At $K = 10^8$: empirical difference $= 0.1063$, matching to <strong>0.1%</strong>.</p>
                        </li>
                        <li><strong>What is the distribution of $\omega$ conditional on primality?</strong>
                            Preliminary analysis at $K = 10^6$ shows the variance is also elevated: PC composites have
                            12% higher variance than CC composites (0.491 vs 0.439).</li>
                        <li><strong>Decomposition: small primes vs. large prime cofactors</strong>
                            <p>The full bias decomposes into two competing effects. At $K = 10^9$ (where $\sqrt{N} = 77{,}459$):</p>
                            <table class="data-table" style="margin: 16px 0; font-size: 0.9rem;">
                                <tr><th>Component</th><th>PC</th><th>CC</th><th>Diff</th></tr>
                                <tr><td>$\omega_{\text{small}}$ (factors $\leq \sqrt{N}$)</td><td>2.231</td><td>2.136</td><td>$+0.095$</td></tr>
                                <tr><td>Has large prime factor</td><td>67.6%</td><td>68.8%</td><td>$-0.012$</td></tr>
                                <tr><td><strong>Full $\omega$</strong></td><td>2.907</td><td>2.824</td><td>$+0.083$</td></tr>
                            </table>
                            <p>Small-prime bias: <strong>4.4%</strong>, reduced to <strong>2.93%</strong> by large-prime effect (13% reduction).
                            CC composites are more likely to have a large prime cofactor, partially offsetting the small-prime bias.
                            (Computation: 11 min on DGX Spark.)</p>
                        </li>
                    </ol>

                    <h2>5.4 Why This Is Useful</h2>
                    <ul>
                        <li><strong>For prime-testing heuristics:</strong> Composite partners of primes are more likely
                            to have many small factors.</li>
                        <li><strong>For understanding conditioned populations:</strong> A clean example of how conditioning
                            creates statistical artifacts.</li>
                        <li><strong>As a pedagogical example:</strong> The derivation illustrates the interplay between
                            rigor and heuristic in analytic number theory.</li>
                    </ul>

                    <h2>5.5 Conclusion</h2>
                    <p>
                        We have documented a 3% selection bias in the number of distinct prime factors of composite numbers
                        adjacent to primes. The phenomenon is simple, the explanation is elementary, and the quantitative
                        agreement is satisfying. Sometimes the most instructive results are those that confirm what "should"
                        be true&mdash;and measure exactly how true it is.
                    </p>
                </div>
            </div>
        </div>
    </div>

    <footer>
        <div class="container">
            <p>
                <a href="https://github.com/bmdragos/twin-prime-selection-bias">View on GitHub</a>
                &nbsp;&middot;&nbsp;
                Built with Plotly.js and MathJax
            </p>
        </div>
    </footer>

    <script>
        // Tab functionality
        document.querySelectorAll('.tab-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                const tabId = btn.dataset.tab;

                // Update buttons
                document.querySelectorAll('.tab-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');

                // Update content
                document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active'));
                document.getElementById(tabId).classList.add('active');

                // Re-render MathJax
                if (window.MathJax) {
                    MathJax.typesetPromise();
                }
            });
        });

        // Navigation active state
        document.querySelectorAll('nav a').forEach(link => {
            link.addEventListener('click', function(e) {
                if (this.getAttribute('href').startsWith('#')) {
                    document.querySelectorAll('nav a').forEach(l => l.classList.remove('active'));
                    this.classList.add('active');
                }
            });
        });

        const plotlyConfig = { responsive: true, displayModeBar: false };
        const plotlyLayout = {
            paper_bgcolor: 'rgba(0,0,0,0)',
            plot_bgcolor: 'rgba(0,0,0,0)',
            font: { family: 'Inter, sans-serif', color: '#e5e5e5' },
            margin: { t: 40, r: 40, b: 60, l: 60 },
            xaxis: { gridcolor: '#2a2a2a', zerolinecolor: '#2a2a2a' },
            yaxis: { gridcolor: '#2a2a2a', zerolinecolor: '#2a2a2a' }
        };

        // Chart 1: Bias Stability
        Plotly.newPlot('chart-stability', [{
            x: ['10^7', '10^8', '10^9'],
            y: [2.956, 2.940, 2.933],
            type: 'scatter',
            mode: 'lines+markers',
            marker: { size: 12, color: '#22c55e' },
            line: { width: 3, color: '#22c55e' },
            name: 'Selection Bias %',
            hovertemplate: 'K = %{x}<br>Bias: %{y:.3f}%<extra></extra>'
        }], {
            ...plotlyLayout,
            title: { text: 'Selection Bias vs Sample Size', font: { size: 16 } },
            xaxis: { ...plotlyLayout.xaxis, title: 'K (number of pairs)' },
            yaxis: { ...plotlyLayout.yaxis, title: 'Bias %', range: [2.8, 3.1] }
        }, plotlyConfig);

        // Chart 2: State Distribution
        Plotly.newPlot('chart-distribution', [
            { x: ['10^7', '10^8', '10^9'], y: [2.81, 2.26, 1.72], name: 'PP', type: 'bar', marker: { color: '#22c55e' } },
            { x: ['10^7', '10^8', '10^9'], y: [15.01, 13.62, 12.25], name: 'PC', type: 'bar', marker: { color: '#3b82f6' } },
            { x: ['10^7', '10^8', '10^9'], y: [15.00, 13.62, 12.25], name: 'CP', type: 'bar', marker: { color: '#8b5cf6' } },
            { x: ['10^7', '10^8', '10^9'], y: [67.18, 70.50, 73.77], name: 'CC', type: 'bar', marker: { color: '#f59e0b' } }
        ], {
            ...plotlyLayout,
            title: { text: 'State Distribution by K', font: { size: 16 } },
            xaxis: { ...plotlyLayout.xaxis, title: 'K (number of pairs)' },
            yaxis: { ...plotlyLayout.yaxis, title: 'Percentage %' },
            barmode: 'stack',
            legend: { orientation: 'h', y: -0.15 }
        }, plotlyConfig);

        // Chart 3: Mean Omega by State
        Plotly.newPlot('chart-omega', [
            { x: ['PP', 'PC', 'CP', 'CC'], y: [1.0, 1.0, 2.9068, 2.8239], name: 'omega(a)', type: 'bar', marker: { color: '#3b82f6' } },
            { x: ['PP', 'PC', 'CP', 'CC'], y: [1.0, 2.9067, 1.0, 2.8239], name: 'omega(b)', type: 'bar', marker: { color: '#8b5cf6' } }
        ], {
            ...plotlyLayout,
            title: { text: 'Mean Omega by State (K=10^9)', font: { size: 16 } },
            xaxis: { ...plotlyLayout.xaxis, title: 'State' },
            yaxis: { ...plotlyLayout.yaxis, title: 'Mean omega' },
            barmode: 'group',
            legend: { orientation: 'h', y: -0.15 }
        }, plotlyConfig);

        // Chart 4: Window Stability
        Plotly.newPlot('chart-windows', [{
            x: ['Full [1,K]', '[K/2, K]', '[0.9K, K]', '[0.99K, K]'],
            y: [2.9326, 3.0024, 3.0027, 2.9938],
            type: 'bar',
            marker: { color: ['#3b82f6', '#22c55e', '#22c55e', '#22c55e'] },
            text: ['2.93%', '3.00%', '3.00%', '2.99%'],
            textposition: 'outside'
        }], {
            ...plotlyLayout,
            title: { text: 'Selection Bias by Window (K=10^9)', font: { size: 16 } },
            xaxis: { ...plotlyLayout.xaxis, title: 'Window' },
            yaxis: { ...plotlyLayout.yaxis, title: 'Bias %', range: [2.7, 3.2] }
        }, plotlyConfig);

        // Chart 5: Baseline Comparisons
        Plotly.newPlot('chart-baselines', [{
            x: ['PC composite', 'Unconditional', 'CC composite'],
            y: [2.9067, 2.8357, 2.8239],
            type: 'bar',
            marker: { color: ['#3b82f6', '#888888', '#f59e0b'] },
            text: ['2.907', '2.836', '2.824'],
            textposition: 'outside'
        }], {
            ...plotlyLayout,
            title: { text: 'Mean Omega by Population (K=10^9)', font: { size: 16 } },
            xaxis: { ...plotlyLayout.xaxis, title: 'Population' },
            yaxis: { ...plotlyLayout.yaxis, title: 'Mean omega', range: [2.75, 2.95] }
        }, plotlyConfig);

        // Chart 6: Generalization Across Patterns
        Plotly.newPlot('chart-generalization', [
            {
                x: ['Twin Primes<br>(6k-1, 6k+1)', 'Sophie Germain<br>(n, 2n+1)', 'Cousin Primes<br>(n, n+4)'],
                y: [0.1065, 0.273, 0.1065],
                name: 'Predicted',
                type: 'bar',
                marker: { color: 'rgba(59, 130, 246, 0.7)', line: { color: '#3b82f6', width: 2 } },
                text: ['0.1065', '0.273', '0.1065'],
                textposition: 'outside'
            },
            {
                x: ['Twin Primes<br>(6k-1, 6k+1)', 'Sophie Germain<br>(n, 2n+1)', 'Cousin Primes<br>(n, n+4)'],
                y: [0.1074, 0.272, 0.1063],
                name: 'Empirical',
                type: 'bar',
                marker: { color: 'rgba(34, 197, 94, 0.7)', line: { color: '#22c55e', width: 2 } },
                text: ['0.1074', '0.272', '0.1063'],
                textposition: 'outside'
            }
        ], {
            ...plotlyLayout,
            title: { text: 'Predicted vs Empirical Bias Across Prime Patterns', font: { size: 16 } },
            xaxis: { ...plotlyLayout.xaxis, title: '' },
            yaxis: { ...plotlyLayout.yaxis, title: 'E[omega | prime] - E[omega | composite]', range: [0, 0.32] },
            barmode: 'group',
            legend: { orientation: 'h', y: 1.1 },
            annotations: [
                { x: 'Twin Primes<br>(6k-1, 6k+1)', y: 0.115, text: '0.8% error', showarrow: false, font: { size: 11, color: '#888' } },
                { x: 'Sophie Germain<br>(n, 2n+1)', y: 0.29, text: '0.4% error', showarrow: false, font: { size: 11, color: '#888' } },
                { x: 'Cousin Primes<br>(n, n+4)', y: 0.115, text: '0.1% error', showarrow: false, font: { size: 11, color: '#888' } }
            ]
        }, plotlyConfig);

        // Chart 7: Convergence of Sum
        const primes = [5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79];
        const cumSum = [];
        let runningSum = 0;
        primes.forEach(p => {
            runningSum += 1 / (p * (p - 1));
            cumSum.push(runningSum);
        });

        Plotly.newPlot('chart-convergence', [
            {
                x: primes,
                y: cumSum,
                type: 'scatter',
                mode: 'lines+markers',
                marker: { size: 8, color: '#3b82f6' },
                line: { width: 2, color: '#3b82f6' },
                name: 'Cumulative sum',
                hovertemplate: 'p = %{x}<br>Sum = %{y:.4f}<extra></extra>'
            },
            {
                x: [0, 85],
                y: [0.1065, 0.1065],
                type: 'scatter',
                mode: 'lines',
                line: { width: 2, color: '#22c55e', dash: 'dash' },
                name: 'Limit = 0.1065'
            }
        ], {
            paper_bgcolor: 'rgba(0,0,0,0)',
            plot_bgcolor: 'rgba(0,0,0,0)',
            font: { family: 'Inter, sans-serif', color: '#e5e5e5' },
            margin: { t: 40, r: 40, b: 60, l: 60 },
            title: { text: 'Convergence of Sum 1/[p(p-1)] for Twin Primes', font: { size: 16 } },
            xaxis: { title: 'Prime p', type: 'linear', range: [0, 85], gridcolor: '#2a2a2a', zerolinecolor: '#2a2a2a' },
            yaxis: { title: 'Cumulative sum', range: [0, 0.12], gridcolor: '#2a2a2a', zerolinecolor: '#2a2a2a' },
            legend: { orientation: 'h', y: -0.15 },
            annotations: [
                { x: 5, y: 0.05, text: 'p=5: 47% of total', showarrow: true, arrowhead: 2, ax: 40, ay: 30, font: { size: 11, color: '#888' } },
                { x: 17, y: 0.093, text: 'First 5 primes: 87%', showarrow: true, arrowhead: 2, ax: 40, ay: -25, font: { size: 11, color: '#888' } }
            ]
        }, plotlyConfig);

        // Chart 8: Omega Decomposition
        Plotly.newPlot('chart-decomposition', [
            {
                x: ['PC composites', 'CC composites'],
                y: [2.231, 2.136],
                name: 'omega_small (factors <= sqrt(N))',
                type: 'bar',
                marker: { color: '#3b82f6' }
            },
            {
                x: ['PC composites', 'CC composites'],
                y: [0.676, 0.688],
                name: 'Large prime indicator',
                type: 'bar',
                marker: { color: '#8b5cf6' }
            }
        ], {
            ...plotlyLayout,
            title: { text: 'Omega Decomposition at K=10^9', font: { size: 16 } },
            xaxis: { ...plotlyLayout.xaxis, title: '' },
            yaxis: { ...plotlyLayout.yaxis, title: 'Value' },
            barmode: 'stack',
            legend: { orientation: 'h', y: -0.15 },
            annotations: [
                { x: 'PC composites', y: 2.95, text: 'Total: 2.907', showarrow: false, font: { size: 12, color: '#e5e5e5' } },
                { x: 'CC composites', y: 2.87, text: 'Total: 2.824', showarrow: false, font: { size: 12, color: '#e5e5e5' } },
                { x: 0.5, y: 1.5, text: 'Small-prime bias: +4.4%<br>Large-prime offset: -13%<br>Net: +2.93%',
                  showarrow: false, font: { size: 11, color: '#888' }, align: 'left',
                  xanchor: 'center', bgcolor: 'rgba(30,30,30,0.9)', borderpad: 8 }
            ]
        }, plotlyConfig);
    </script>
</body>
</html>
